{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Tutorial 3: Convolutional Neural Networks"],"metadata":{"id":"YImIHqSsqXEm"}},{"cell_type":"markdown","source":["In this tutorial we will:\n","\n","\n","1.   Revise how tensors work and how images are represented as tensors\n","2.   Load and visualize a dataset\n","3.   Build and train a simple MLP classifier\n","4.   Standardize the data distribution and achieve better accuracy\n","5.   Understand how convolutional works on images\n","6.   Build and train a simple CNN classifier\n","\n","\n","\n","\n"],"metadata":{"id":"5G77nVbEsJii"}},{"cell_type":"markdown","source":["General tips for PyTorch:\n","\n","The documentation is very well written and is your best friend. Get familiar with it and use it often. https://pytorch.org/docs/stable/index.html\n","\n","PyTorch has a big userbase, if you ever encounter an error, be sure someone else has encountered it before. Don't be afraid to Google it to find the answer."],"metadata":{"id":"wlR89oKZxhTf"}},{"cell_type":"markdown","source":["## 1. Images as torch tensors\n","\n","Let's have a look at how images are represented as tensors"],"metadata":{"id":"Z54uaopPstRs"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torchsummary import summary\n","\n","import numpy as np\n","import time"],"metadata":{"id":"9bpWZY-bxb_P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use GPU if available\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"],"metadata":{"id":"hgmGqNwbxdIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["If the device is cpu, go to Runtime -> Change runtime type -> T4 GPU -> Save"],"metadata":{"id":"1M_FrEbrGGHQ"}},{"cell_type":"markdown","source":["### What's special about torch tensors?\n","\n","1.   Torch tensors can be used on GPUs which are much faster than CPUs at large parallel computations\n","2.   Torch automatically keeps track of the gradient information"],"metadata":{"id":"XIB4uYY1H8H6"}},{"cell_type":"code","source":["# CPU vs GPU\n","\n","dim=6000\n","\n","x=torch.randn(dim,dim)\n","y=torch.randn(dim,dim)\n","start_time = time.time()\n","z=torch.matmul(x,y)\n","elapsed_time = time.time() - start_time\n","print('CPU_time = ', elapsed_time)\n","\n","\n","x=torch.randn(dim,dim,device=device)\n","y=torch.randn(dim,dim,device=device)\n","start_time = time.time()\n","z=torch.matmul(x,y)\n","elapsed_time = time.time() - start_time\n","print('GPU_time = ',elapsed_time)"],"metadata":{"id":"69imm9MWH78b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Torch tensors automatically keep track of the gradient information\n","x=torch.rand(64, requires_grad=True)\n","\n","f1=4*x\n","f2=6*x\n","\n","function=(f1+f2).sum()\n","\n","function.backward()\n","print(x.grad)\n","\n","x = x.detach()\n","print(x.grad)"],"metadata":{"id":"3R8jJMR3IBM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's see how we can load images with to numpy arrays"],"metadata":{"id":"Vzl_2YOoz-ej"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import requests\n","import cv2\n","from PIL import Image\n","from io import BytesIO\n","\n","# Display the image from a URL\n","url = \"https://www.jpchacha.com/blog/content/00000002/lena_256.jpg\"\n","response = requests.get(url, allow_redirects=True)\n","img = Image.open(BytesIO(response.content))\n","img_array = np.array(img)\n","\n","plt.imshow(img_array)\n","print(img_array.shape)"],"metadata":{"id":"_gKvXSH30RPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(img_array)"],"metadata":{"id":"ItA55GK5Xaaz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["By default, numpy loads images with the \"height, width, channels\" dimension format. When processing images with torch, it expects them to have the following shape:\n","\n","[B, C, H, W]\n","\n","Where:\n","\n","*  B -> Dimension of the batch size\n","*  C -> Number of channels for each image (RGB images have 3, black and white images 1)\n","*  H -> Height of each image in the batch\n","*  W -> Width of each image in the batch\n","\n","Let's reshape the image accordingly."],"metadata":{"id":"Ng1w1sOmG5GW"}},{"cell_type":"code","source":["img_tensor = torch.from_numpy(img_array)\n","img_tensor = torch.transpose(img_tensor, 0, 2).unsqueeze(0)\n","\n","print(img_tensor)\n","print(img_tensor.shape)"],"metadata":{"id":"-0xdVnpFHSZx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The value of the pixels are in Unsigned Integer 8 format, having values ranging from 0 to 255. When we process the images however, we will want to have floats in in an easier to operate range for neural networks.\n","\n","The batch size here is 1 because we only have 1 image in this tensor.\n","\n","The height and width are 256. In case of storing multiple images in the same tensor, they must all have the same shapes. If they don't we can apply some [padding](https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html)"],"metadata":{"id":"Y5JSy113Hscf"}},{"cell_type":"markdown","source":["## 2. Load and create a dataset with Torch"],"metadata":{"id":"6iK303Szs_da"}},{"cell_type":"markdown","source":["Torch has some utilities that allow us to load and create datasets very easily. Let's load the Fashion MNIST dataset"],"metadata":{"id":"KMELAOkaJdlk"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor"],"metadata":{"id":"kKLxObVtJkKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Download training data from open datasets.\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor(),\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=ToTensor(),\n",")"],"metadata":{"id":"xMRllo-wtEs3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 64\n","\n","# Get length of training and test dataset\n","print(f\"The training data has: {len(training_data)} samples\")\n","print(f\"The test data has: {len(test_data)} samples\")\n","\n","# Let's investigate what a data entry is like\n","print(f\"Each data sample is a {type(training_data[0])} of length {len(training_data[0])}\")\n","print(f\"The first entry is a {type(training_data[0][0])} of shape {training_data[0][0].shape}\")\n","print(f\"The second entry is the label: {training_data[0][1]}\\n\")"],"metadata":{"id":"82QDohk3tGbG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now that we have downloaded the data, let's move it into pytorch dataloaders"],"metadata":{"id":"kw4RFHD6JvNU"}},{"cell_type":"code","source":["# Let's load the dataset into PyTorch dataloaders\n","train_dataloader = DataLoader(\n","    training_data,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","test_dataloader = DataLoader(\n","    test_data,\n","    batch_size=batch_size\n",")\n","\n","for X, y in test_dataloader:\n","    print(f\"Shape of X [B, C, H, W]: {X.shape}\")\n","    print(f\"Shape of y: {y.shape} {y.dtype}\")\n","    break"],"metadata":{"id":"_ltKOBjitH2m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset visualization"],"metadata":{"id":"KLuz56hatJ0Q"}},{"cell_type":"markdown","source":["Visualize the classes of the dataset"],"metadata":{"id":"XgNj2kLdMh2e"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","%matplotlib inline\n","\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################"],"metadata":{"id":"rk2TASdetJeF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. Build a simple MLP classifier"],"metadata":{"id":"hELV3bqftObA"}},{"cell_type":"markdown","source":["Before moving to CNNs, let's create a simple MLP classifier. To work with images. In order for the MLP to process an image, you will have to flatten the input image to a single dimension. Have a look on pytorch documentation for nn.Flatten"],"metadata":{"id":"l_76dldHK8-U"}},{"cell_type":"code","source":["# Define model\n","class MLP(nn.Module):\n","\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","\n","model = MLP().to(device)\n","\n","def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(model)\n","print(count_parameters(model))"],"metadata":{"id":"XqQTsP1ztQjn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"],"metadata":{"id":"qinUZ4F_tSOL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's define a train and test function"],"metadata":{"id":"vfzI0giVMBZe"}},{"cell_type":"code","source":["def train(dataloader, model, loss_fn, optimizer):\n","\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################"],"metadata":{"id":"RIuTcfzgtTle"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test(dataloader, model, loss_fn):\n","\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n"],"metadata":{"id":"MouxULkMtUVZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"id":"KA8WC7uitVIy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4. Can we get better performance?\n","\n","Hopefully got got accuracy better than random (10%), if not, something is wrong with your code. But can we get better performance than this?\n","Let's try to standardize the data. We can do this by subtracting the mean and dividing by the standard deviation"],"metadata":{"id":"CMbFoSpStXzo"}},{"cell_type":"code","source":["training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=ToTensor()\n",")\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    training_data,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","\n","mean = 0.\n","std = 0.\n","\n","# Calculate the mean and standard deviation of the training data\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################"],"metadata":{"id":"g59yzAf3tanX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now normalize the data. Have a look at transforms.Compose to concatenate multiple sequential data transformations\n","# transforms.Normalize is what you want to use here\n","\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","# data_transforms = your code here\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","\n","# Download training data from open datasets.\n","training_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=True,\n","    download=True,\n","    transform=data_transforms,\n",")\n","\n","# Download test data from open datasets.\n","test_data = datasets.FashionMNIST(\n","    root=\"data\",\n","    train=False,\n","    download=True,\n","    transform=data_transforms,\n",")\n","\n","train_dataloader = torch.utils.data.DataLoader(\n","    training_data,\n","    batch_size=batch_size,\n","    shuffle=True,\n",")\n","\n","test_dataloader = torch.utils.data.DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=True\n",")\n","\n","mean = 0.\n","std = 0.\n","for images, _ in train_dataloader:\n","    batch_samples = images.size(0)\n","    images = images.view(batch_size, -1)\n","    mean += images.mean(1).sum()\n","    std += images.std(1).sum()\n","\n","mean /= len(train_dataloader.dataset)\n","std /= len(train_dataloader.dataset)\n","\n","\n","print(mean, std)"],"metadata":{"id":"AuZOSHgytdGl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's train again\n","model = MLP().to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","\n","epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"id":"MQRxkJuQtd0b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Deep learning models are only as good as the data they are trained on\n","With simple data normalization we managed to increase performance significantly"],"metadata":{"id":"iXMLi-1KtgeH"}},{"cell_type":"markdown","source":["## 5. How does convolution work on images?"],"metadata":{"id":"2sg31r7qShjo"}},{"cell_type":"markdown","source":["In the ancient days of classical computer vision, convolution was used to extract edges and features from images. This was done with predefined filters, such as Sobel or Laplacian operators, to detect edges, corners, and other basic visual features. The resulting images were then processed further through techniques like thresholding, feature matching, and clustering. These handcrafted features were critical for tasks like object detection and recognition, but they lacked the adaptability and performance of modern deep learning approaches.\n","\n","Let's see how an edge detector like the sobel filter worked in practice. If you want to know more, have a look [here](http://www.theobjects.com/dragonfly/dfhelp/2021-1/Content/Viewing%20and%20Processing%20Images/Image%20Filtering/Edge%20Detection%20Filters.htm)."],"metadata":{"id":"YHRzcjMxZ3uH"}},{"cell_type":"code","source":["# Display the image from a URL\n","import requests\n","from PIL import Image\n","from io import BytesIO\n","\n","url = \"https://i.sstatic.net/MCZ7o.jpg\"\n","response = requests.get(url)\n","img = Image.open(BytesIO(response.content))\n","\n","img_array = np.array(img)\n","plt.imshow(img_array)\n","\n","# Permute is similar to transpose but allows us to reorder multiple dimensions\n","# Unsqueeze is creating a new dimension in the position we ask it to (in this case in the batch_size position)\n","img_tensor = torch.from_numpy(img_array).permute(2,0,1).unsqueeze(0)\n","print(img_tensor.shape)"],"metadata":{"id":"uoVxMN1eTvCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The image is black and white. We only need a single channel, and we need to transform its pixels in the range [0,1] float\n","\n","img_tensor = torch.mean(img_tensor.float() / 255.0, dim=1, keepdim=True)\n","print(img_tensor)\n","print(img_tensor.shape)"],"metadata":{"id":"c41Tk9-JYBH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Sobel kernels\n","sobel_x = torch.tensor([[[[-1, 0, 1],\n","                          [-2, 0, 2],\n","                          [-1, 0, 1]]]], dtype=torch.float32)\n","\n","sobel_y = torch.tensor([[[[-1, -2, -1],\n","                          [0,  0,  0],\n","                          [1,  2,  1]]]], dtype=torch.float32)\n","\n","# Apply Sobel filter in x direction\n","grad_x = F.conv2d(img_tensor, sobel_x, padding=1)\n","\n","# Apply Sobel filter in y direction\n","grad_y = F.conv2d(img_tensor, sobel_y, padding=1)\n","\n","# Compute magnitude\n","grad_magnitude = torch.sqrt(grad_x ** 2 + grad_y ** 2)\n","\n","grad_x_np = grad_x.squeeze().detach().numpy()\n","grad_y_np = grad_y.squeeze().detach().numpy()\n","grad_magnitude_np = grad_magnitude.squeeze().detach().numpy()\n","\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 3, 1)\n","plt.title(\"Sobel X\")\n","plt.imshow(grad_x_np, cmap='gray')\n","\n","plt.subplot(1, 3, 2)\n","plt.title(\"Sobel Y\")\n","plt.imshow(grad_y_np, cmap='gray')\n","\n","plt.subplot(1, 3, 3)\n","plt.title(\"Gradient Magnitude\")\n","plt.imshow(grad_magnitude_np, cmap='gray')\n","\n","plt.show()"],"metadata":{"id":"1qDWk62eVZbU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6. Convolutional Neural Networks\n","\n","Instead of using pre-defined filters, convolutional neural networks (CNNs) learn their own filters directly from data during training. These learned filters automatically adapt to capture relevant features like edges, textures, and complex patterns, enabling more accurate and scalable feature extraction compared to classical methods."],"metadata":{"id":"O0FXZtYsYWVK"}},{"cell_type":"markdown","source":["CNNs are the predominant neural networks used in computer vision*\n","\n","Their main building blocks are convolutions, used for processing information and deriving more complex features, and pooling layers for aggregating and downsampling information.\n","\n","We will now modify the MLP network we used in tutorial 3, and make a very simple CNN.\n","\n","*Vision Transformers (ViT) now outperform CNNs on tasks with large data availability (ImageNet for example). We will talk about transformers in a future lecture."],"metadata":{"id":"zRbUp4vC_00h"}},{"cell_type":"markdown","source":["## Build a simple CNN\n","Let's now build a simple Convolutional Neural Network (CNN) for the same task. The main building blocks of CNNs are convolutions and pooling layers. Have a look at the PyTorch documentation to see how they are defined and what parameters they take as input.\n","\n","[Convolution](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#conv2d)\n","\n","[Avg Pooling layer](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)\n","\n","\n","### Build a CNN with the following layers:\n","* Convolution(in_channel, out_channel, kernel_size, stride, padding)\n","* Relu\n","* Average pooling layer\n","* Convolution(in_channel, out_channel, kernel_size, stride, padding)\n","* Relu\n","* Flatten\n","* Linear(flattened_dimension, 10)"],"metadata":{"id":"K5OwkuV2_NqU"}},{"cell_type":"code","source":["class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        ########################################################################\n","        #                              YOUR CODE HERE                          #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","\n","model = SimpleCNN().to(device)\n","\n","summary(model, (1,28,28))"],"metadata":{"id":"uBuZoQESYVKp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","\n","epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"id":"YNSynUTQ_ghR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Build an improved CNN\n","\n","Feel free to experiment with the following blocks:\n","\n","###Convolutions\n","* [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n","\n","###Pooling blocks\n","* [AvgPool2d](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#avgpool2d)\n","* [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#maxpool2d)\n","\n","###Activation functions\n","* [ReLU](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu)\n","* [LeakyReLU](https://pytorch.org/docs/stable/generated/torch.nn.LeakyReLU.html#leakyrelu)\n","* [GELU](https://pytorch.org/docs/stable/generated/torch.nn.GELU.html#gelu)\n","\n","###Dropout\n","* [Dropout](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html#dropout)\n","* [Dropout2d](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html#dropout2d)\n","\n","###Normalization layers\n","* [BatchNorm2d](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#batchnorm2d)\n","* [LayerNorm](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html#layernorm)\n","\n","# Challenge\n"," Improve performance as much as you can. Can you get close to ~90% accuracy? Only change the CNN, do **not** change optimizers, data transformations or number of epochs. Feel free to change as many layers as you want, make the network wider, deeper whatever you like. Try to keep your network relatively small - don't make it larger than the original MLP (670K params)\n","\n","\n","Again, PyTorch documentation is your best friend\n","https://pytorch.org/docs/stable/index.html\n"],"metadata":{"id":"TkWavPug_jKb"}},{"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        ########################################################################\n","        #                            IMPROVE CODE HERE                         #\n","        ########################################################################\n","\n","\n","\n","        ########################################################################\n","        #                             END OF YOUR CODE                         #\n","        ########################################################################\n","\n","model = CNN().to(device)\n","\n","summary(model, (1,28,28))"],"metadata":{"id":"-qt-5uvg_li5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n","\n","epochs = 5\n","for t in range(epochs):\n","    print(f\"Epoch {t+1}\\n-------------------------------\")\n","    train(train_dataloader, model, loss_fn, optimizer)\n","    test(test_dataloader, model, loss_fn)\n","print(\"Done!\")"],"metadata":{"id":"g0wgoCOa_oUI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# More advanced CNNs\n","\n","There exists many different types of CNN models, one of the most common backbones used is the ResNet. Have a look at how more advanced neural networks are built. You can find more here:\n","\n","https://github.com/kuangliu/pytorch-cifar"],"metadata":{"id":"V7xusSsR_rpT"}},{"cell_type":"code","source":["'''ResNet in PyTorch.\n","\n","For Pre-activation ResNet, see 'preact_resnet.py'.\n","\n","Reference:\n","[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n","    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n","'''\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = nn.Conv2d(\n","            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n","                               stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, self.expansion *\n","                               planes, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = F.relu(self.bn2(self.conv2(out)))\n","        out = self.bn3(self.conv3(out))\n","        out += self.shortcut(x)\n","        out = F.relu(out)\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n","                               stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(512*block.expansion, num_classes)\n","\n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        out = F.relu(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n","\n","\n","def ResNet18():\n","    return ResNet(BasicBlock, [2, 2, 2, 2])\n","\n","\n","def ResNet34():\n","    return ResNet(BasicBlock, [3, 4, 6, 3])\n","\n","\n","def ResNet50():\n","    return ResNet(Bottleneck, [3, 4, 6, 3])\n","\n","\n","def ResNet101():\n","    return ResNet(Bottleneck, [3, 4, 23, 3])\n","\n","\n","def ResNet152():\n","    return ResNet(Bottleneck, [3, 8, 36, 3])\n","\n","\n","def test():\n","    net = ResNet18()\n","    y = net(torch.randn(1, 3, 32, 32))\n","    print(y.size())\n","\n","\n","\n","model = ResNet18().to(device)\n","\n","summary(model, (3,32,32))"],"metadata":{"id":"5_33B2T8_vJv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Optional\n","\n","1.   If you want to learn more about how CNNs work, try visualizing how their feature extraction pipeline works. Refer to: https://arxiv.org/abs/1311.2901\n","2.   Beyond image classification, there are many other tasks that CNNs are used for, such as image segmentation, object detection, super resolution and more. Have a look at the U-Net for image segmentation [[1]](https://github.com/milesial/Pytorch-UNet) [[2]](https://arxiv.org/abs/1505.04597)"],"metadata":{"id":"XNkEjcRvATnc"}}]}